<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/data_process/file_count.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/data_process/file_count.py" />
              <option name="originalContent" value="import os&#10;# 统计标签与图片对应情况&#10;&#10;# 获取项目根目录（假设 data_process 和 ISICDM2025_dataset 同级）&#10;PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))&#10;&#10;# 统计训练集和验证集图片数量&#10;train_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;images&quot;, &quot;train&quot;)&#10;val_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;images&quot;, &quot;val&quot;)&#10;&#10;train_imgs = [f for f in os.listdir(train_dir) if f.lower().endswith('.png')]&#10;val_imgs = [f for f in os.listdir(val_dir) if f.lower().endswith('.png')]&#10;&#10;print(f&quot;训练集图片数量: {len(train_imgs)}&quot;)&#10;print(f&quot;验证集图片数量: {len(val_imgs)}&quot;)&#10;&#10;# 统计训练集和验证集标签数量&#10;train_label_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;labels&quot;, &quot;train&quot;)&#10;val_label_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;labels&quot;, &quot;val&quot;)&#10;train_labels = [f for f in os.listdir(train_label_dir) if f.lower().endswith('.txt')]&#10;val_labels = [f for f in os.listdir(val_label_dir) if f.lower().endswith('.txt')]&#10;&#10;print(f&quot;训练集标签数量: {len(train_labels)}&quot;)&#10;print(f&quot;验证集标签数量: {len(val_labels)}&quot;)&#10;" />
              <option name="updatedContent" value="import os&#10;# 统计标签与图片对应情况&#10;&#10;# 获取项目根目录（假设 data_process 和 ISICDM2025_dataset 同级）&#10;PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))&#10;&#10;# 统计训练集和验证集图片数量&#10;train_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;images&quot;, &quot;train&quot;)&#10;val_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;images&quot;, &quot;val&quot;)&#10;&#10;train_imgs = [f for f in os.listdir(train_dir) if f.lower().endswith('.png')]&#10;val_imgs = [f for f in os.listdir(val_dir) if f.lower().endswith('.png')]&#10;&#10;print(f&quot;训练集图片数量: {len(train_imgs)}&quot;)&#10;print(f&quot;验证集图片数量: {len(val_imgs)}&quot;)&#10;&#10;# 统计训练集和验证集标签数量&#10;train_label_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;labels&quot;, &quot;train&quot;)&#10;val_label_dir = os.path.join(PROJECT_ROOT, &quot;ISICDM2025_dataset&quot;, &quot;labels&quot;, &quot;val&quot;)&#10;train_labels = [f for f in os.listdir(train_label_dir) if f.lower().endswith('.txt')]&#10;val_labels = [f for f in os.listdir(val_label_dir) if f.lower().endswith('.txt')]&#10;&#10;print(f&quot;训练集标签数量: {len(train_labels)}&quot;)&#10;print(f&quot;验证集标签数量: {len(val_labels)}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/scripts/mydataset.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scripts/mydataset.py" />
              <option name="originalContent" value="# mydataset.py&#10;import cv2&#10;import numpy as np&#10;from ultralytics.data.dataset import YOLODataset&#10;&#10;&#10;class CenterCropDataset(YOLODataset):&#10;    &quot;&quot;&quot;中心裁剪 + 条件填充 数据集（最小侵入式）。&#10;&#10;    目标：保留 YOLODataset 原有 transforms / augment / letterbox / mosaic 等流程，只在进入 transforms 前做一次：&#10;      1. 若两边都 &gt; imgsz -&gt; 以第一个 bbox 中心为参考裁成 imgsz × imgsz。&#10;      2. 若仅一边 &gt; imgsz -&gt; 裁剪该超限边到 imgsz，另一边若 &lt; imgsz 则直接 pad 到 imgsz，得到 imgsz × imgsz。&#10;      3. 若两边都 &lt;= imgsz -&gt; 保持原图（不强制 pad，交给后续官方 LetterBox 处理）。&#10;    这样：只有发生“裁剪”时才强制输出正方形；纯小图不提前 pad，避免重复 letterbox。&#10;&#10;    裁剪中心：若存在标签，取第一个 bbox 的中心 (cx, cy)，否则取图像中心。&#10;    标签：对被裁剪 &amp; 填充后的图像重新平移+截断+过滤(size&gt;2像素)并重新归一化到当前图像尺寸 (h_new, w_new)。&#10;&#10;    额外元数据：&#10;      - crop_offset: (top, left) 相对原始整图的起始裁剪偏移（即裁后图左上角在原图中的坐标）。&#10;      - full_ori_shape: (h0, w0) 原始整图尺寸。&#10;      - pad_offset: (pad_top, pad_left) 若发生内部 pad（仅单边超限场景），记录在裁后再 pad 阶段添加的偏移；否则(0,0)。&#10;      - ori_shape/resized_shape: 裁剪+pad 之后的当前图尺寸（供后续 transforms 使用）。&#10;&#10;    注意：如果需要在推理阶段将预测框还原回原始整图坐标：&#10;        1) 先逆 LetterBox（若使用）得到裁剪+pad 图坐标。&#10;        2) 减掉 pad_offset（如果存在）。&#10;        3) 再加上 crop_offset（top,left）。&#10;        4) 结果即在 full_ori_shape 下的绝对像素坐标。&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, *args, imgsz=1024, **kwargs):&#10;        super().__init__(*args, **kwargs)&#10;        self.crop_imgsz = imgsz&#10;&#10;    # -------------------- 坐标转换辅助 --------------------&#10;    @staticmethod&#10;    def _norm_xywh_to_pixel_xyxy(bboxes, w, h):&#10;        if bboxes.size == 0:&#10;            return bboxes.reshape(0, 4)&#10;        cx = bboxes[:, 0] * w&#10;        cy = bboxes[:, 1] * h&#10;        bw = bboxes[:, 2] * w&#10;        bh = bboxes[:, 3] * h&#10;        x1 = cx - bw / 2&#10;        y1 = cy - bh / 2&#10;        x2 = cx + bw / 2&#10;        y2 = cy + bh / 2&#10;        return np.stack([x1, y1, x2, y2], 1)&#10;&#10;    @staticmethod&#10;    def _pixel_xyxy_to_norm_xywh(bboxes_xyxy, w, h):&#10;        if bboxes_xyxy.size == 0:&#10;            return bboxes_xyxy.reshape(0, 4)&#10;        x1, y1, x2, y2 = [bboxes_xyxy[:, i] for i in range(4)]&#10;        bw = (x2 - x1).clip(min=1e-3)&#10;        bh = (y2 - y1).clip(min=1e-3)&#10;        cx = x1 + bw / 2&#10;        cy = y1 + bh / 2&#10;        return np.stack([cx / w, cy / h, bw / w, bh / h], 1)&#10;&#10;    # -------------------- 核心逻辑 --------------------&#10;    def __getitem__(self, index):&#10;        base_label = self.labels[index]&#10;        # 浅拷贝 + 数组复制，避免污染缓存&#10;        label = {k: (v.copy() if isinstance(v, np.ndarray) else v) for k, v in base_label.items()}&#10;&#10;        img_path = label[&quot;im_file&quot;]&#10;        img = cv2.imread(img_path)&#10;        if img is None:&#10;            raise FileNotFoundError(f&quot;无法读取图像: {img_path}&quot;)&#10;        h0, w0 = img.shape[:2]&#10;        full_ori_shape = (h0, w0)&#10;&#10;        S = self.crop_imgsz&#10;        over_h = h0 &gt; S&#10;        over_w = w0 &gt; S&#10;&#10;        # 默认无裁剪/无 pad 偏移&#10;        top = left = 0&#10;        pad_top = pad_left = 0&#10;&#10;        # 决策逻辑&#10;        if over_h and over_w:&#10;            # 双边均超 -&gt; 取一个 SxS 裁剪窗口&#10;            crop_h = crop_w = S&#10;        elif over_h and not over_w:&#10;            # 仅高超 -&gt; 裁高至 S，宽保持 w0 (&lt;=S?) 若 w0 &lt; S 则后面再 pad 宽到 S&#10;            crop_h = S&#10;            crop_w = w0&#10;        elif over_w and not over_h:&#10;            # 仅宽超 -&gt; 裁宽至 S，高保持 h0 (&lt;=S?) 若 h0 &lt; S 则后面再 pad 高到 S&#10;            crop_w = S&#10;            crop_h = h0&#10;        else:&#10;            # 都不超：不裁不 pad&#10;            crop_h = h0&#10;            crop_w = w0&#10;&#10;        need_crop = over_h or over_w&#10;&#10;        if need_crop:&#10;            bboxes_norm = label[&quot;bboxes&quot;]&#10;            if bboxes_norm.shape[0] &gt; 0:&#10;                cx_center = float(bboxes_norm[0, 0] * w0)&#10;                cy_center = float(bboxes_norm[0, 1] * h0)&#10;            else:&#10;                cx_center = w0 / 2.0&#10;                cy_center = h0 / 2.0&#10;            # 计算裁剪左上&#10;            if over_w:&#10;                left = int(round(cx_center - crop_w / 2))&#10;                left = max(0, min(left, w0 - crop_w))&#10;            if over_h:&#10;                top = int(round(cy_center - crop_h / 2))&#10;                top = max(0, min(top, h0 - crop_h))&#10;            # 执行裁剪&#10;            img = img[top: top + crop_h, left: left + crop_w]&#10;&#10;        h1, w1 = img.shape[:2]&#10;&#10;        # 单边超限情形下：若另一边 &lt; S，需要 pad 到 S（只在发生裁剪场景下执行）&#10;        if need_crop:&#10;            if over_h and not over_w and w1 &lt; S:&#10;                # pad 宽（左右）&#10;                pad_total = S - w1&#10;                pad_left = pad_total // 2&#10;                pad_right = pad_total - pad_left&#10;                img = cv2.copyMakeBorder(img, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(114, 114, 114))&#10;                w1 = S&#10;            elif over_w and not over_h and h1 &lt; S:&#10;                # pad 高（上下）&#10;                pad_total = S - h1&#10;                pad_top = pad_total // 2&#10;                pad_bottom = pad_total - pad_top&#10;                img = cv2.copyMakeBorder(img, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value=(114, 114, 114))&#10;                h1 = S&#10;        # (双边超) 已经 SxS；(双边不超) 保持原形&#10;&#10;        # 处理标签&#10;        bboxes_norm = label[&quot;bboxes&quot;]&#10;        if bboxes_norm.shape[0] &gt; 0:&#10;            boxes_xyxy = self._norm_xywh_to_pixel_xyxy(bboxes_norm, w0, h0)&#10;            if need_crop:&#10;                # 平移（裁剪）&#10;                boxes_xyxy[:, [0, 2]] -= left&#10;                boxes_xyxy[:, [1, 3]] -= top&#10;            # 平移（pad）&#10;            if pad_left or pad_top:&#10;                boxes_xyxy[:, [0, 2]] += pad_left&#10;                boxes_xyxy[:, [1, 3]] += pad_top&#10;            # 截断到当前图尺寸&#10;            boxes_xyxy[:, 0] = boxes_xyxy[:, 0].clip(0, w1)&#10;            boxes_xyxy[:, 2] = boxes_xyxy[:, 2].clip(0, w1)&#10;            boxes_xyxy[:, 1] = boxes_xyxy[:, 1].clip(0, h1)&#10;            boxes_xyxy[:, 3] = boxes_xyxy[:, 3].clip(0, h1)&#10;            # 过滤极小框&#10;            bw = boxes_xyxy[:, 2] - boxes_xyxy[:, 0]&#10;            bh = boxes_xyxy[:, 3] - boxes_xyxy[:, 1]&#10;            valid = (bw &gt; 2) &amp; (bh &gt; 2)&#10;            boxes_xyxy = boxes_xyxy[valid]&#10;            label[&quot;cls&quot;] = label[&quot;cls&quot;][valid]&#10;            bboxes_new = self._pixel_xyxy_to_norm_xywh(boxes_xyxy, w1, h1)&#10;            label[&quot;bboxes&quot;] = bboxes_new.astype(np.float32)&#10;            label[&quot;normalized&quot;] = True&#10;            label[&quot;bbox_format&quot;] = &quot;xywh&quot;&#10;        # 更新形状&#10;        label[&quot;shape&quot;] = (h1, w1)&#10;        label[&quot;img&quot;] = img&#10;        label[&quot;ori_shape&quot;] = (h1, w1)  # 供后续 transforms 使用&#10;        label[&quot;resized_shape&quot;] = (h1, w1)&#10;        label[&quot;crop_offset&quot;] = (top, left)&#10;        label[&quot;pad_offset&quot;] = (pad_top, pad_left)&#10;        label[&quot;full_ori_shape&quot;] = full_ori_shape&#10;&#10;        if self.transforms:&#10;            label = self.transforms(label)&#10;        return label&#10;" />
              <option name="updatedContent" value="# mydataset.py&#10;import cv2&#10;import numpy as np&#10;from ultralytics.data.dataset import YOLODataset&#10;&#10;&#10;class CenterCropDataset(YOLODataset):&#10;    &quot;&quot;&quot;中心裁剪 + 条件填充 数据集（最小侵入式）。&#10;&#10;    目标：保留 YOLODataset 原有 transforms / augment / letterbox / mosaic 等流程，只在进入 transforms 前做一次：&#10;      1. 若两边都 &gt; imgsz -&gt; 以第一个 bbox 中心为参考裁成 imgsz × imgsz。&#10;      2. 若仅一边 &gt; imgsz -&gt; 裁剪该超限边到 imgsz，另一边若 &lt; imgsz 则直接 pad 到 imgsz，得到 imgsz × imgsz。&#10;      3. 若两边都 &lt;= imgsz -&gt; 保持原图（不强制 pad，交给后续官方 LetterBox 处理）。&#10;    这样：只有发生“裁剪”时才强制输出正方形；纯小图不提前 pad，避免重复 letterbox。&#10;&#10;    裁剪中心：若存在标签，取第一个 bbox 的中心 (cx, cy)，否则取图像中心。&#10;    标签：对被裁剪 &amp; 填充后的图像重新平移+截断+过滤(size&gt;2像素)并重新归一化到当前图像尺寸 (h_new, w_new)。&#10;&#10;    额外元数据：&#10;      - crop_offset: (top, left) 相对原始整图的起始裁剪偏移（即裁后图左上角在原图中的坐标）。&#10;      - full_ori_shape: (h0, w0) 原始整图尺寸。&#10;      - pad_offset: (pad_top, pad_left) 若发生内部 pad（仅单边超限场景），记录在裁后再 pad 阶段添加的偏移；否则(0,0)。&#10;      - ori_shape/resized_shape: 裁剪+pad 之后的当前图尺寸（供后续 transforms 使用）。&#10;&#10;    注意：如果需要在推理阶段将预测框还原回原始整图坐标：&#10;        1) 先逆 LetterBox（若使用）得到裁剪+pad 图坐标。&#10;        2) 减掉 pad_offset（如果存在）。&#10;        3) 再加上 crop_offset（top,left）。&#10;        4) 结果即在 full_ori_shape 下的绝对像素坐标。&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, *args, imgsz=1024, **kwargs):&#10;        super().__init__(*args, **kwargs)&#10;        self.crop_imgsz = imgsz&#10;&#10;    # -------------------- 坐标转换辅助 --------------------&#10;    @staticmethod&#10;    def _norm_xywh_to_pixel_xyxy(bboxes, w, h):&#10;        if bboxes.size == 0:&#10;            return bboxes.reshape(0, 4)&#10;        cx = bboxes[:, 0] * w&#10;        cy = bboxes[:, 1] * h&#10;        bw = bboxes[:, 2] * w&#10;        bh = bboxes[:, 3] * h&#10;        x1 = cx - bw / 2&#10;        y1 = cy - bh / 2&#10;        x2 = cx + bw / 2&#10;        y2 = cy + bh / 2&#10;        return np.stack([x1, y1, x2, y2], 1)&#10;&#10;    @staticmethod&#10;    def _pixel_xyxy_to_norm_xywh(bboxes_xyxy, w, h):&#10;        if bboxes_xyxy.size == 0:&#10;            return bboxes_xyxy.reshape(0, 4)&#10;        x1, y1, x2, y2 = [bboxes_xyxy[:, i] for i in range(4)]&#10;        bw = (x2 - x1).clip(min=1e-3)&#10;        bh = (y2 - y1).clip(min=1e-3)&#10;        cx = x1 + bw / 2&#10;        cy = y1 + bh / 2&#10;        return np.stack([cx / w, cy / h, bw / w, bh / h], 1)&#10;&#10;    # -------------------- 核心逻辑 --------------------&#10;    def __getitem__(self, index):&#10;        base_label = self.labels[index]&#10;        # 浅拷贝 + 数组复制，避免污染缓存&#10;        label = {k: (v.copy() if isinstance(v, np.ndarray) else v) for k, v in base_label.items()}&#10;&#10;        img_path = label[&quot;im_file&quot;]&#10;        img = cv2.imread(img_path)&#10;        if img is None:&#10;            raise FileNotFoundError(f&quot;无法读取图像: {img_path}&quot;)&#10;        h0, w0 = img.shape[:2]&#10;        full_ori_shape = (h0, w0)&#10;&#10;        S = self.crop_imgsz&#10;        over_h = h0 &gt; S&#10;        over_w = w0 &gt; S&#10;&#10;        # 默认无裁剪/无 pad 偏移&#10;        top = left = 0&#10;        pad_top = pad_left = 0&#10;&#10;        # 决策逻辑&#10;        if over_h and over_w:&#10;            # 双边均超 -&gt; 取一个 SxS 裁剪窗口&#10;            crop_h = crop_w = S&#10;        elif over_h and not over_w:&#10;            # 仅高超 -&gt; 裁高至 S，宽保持 w0 (&lt;=S?) 若 w0 &lt; S 则后面再 pad 宽到 S&#10;            crop_h = S&#10;            crop_w = w0&#10;        elif over_w and not over_h:&#10;            # 仅宽超 -&gt; 裁宽至 S，高保持 h0 (&lt;=S?) 若 h0 &lt; S 则后面再 pad 高到 S&#10;            crop_w = S&#10;            crop_h = h0&#10;        else:&#10;            # 都不超：不裁不 pad&#10;            crop_h = h0&#10;            crop_w = w0&#10;&#10;        need_crop = over_h or over_w&#10;&#10;        if need_crop:&#10;            bboxes_norm = label[&quot;bboxes&quot;]&#10;            if bboxes_norm.shape[0] &gt; 0:&#10;                cx_center = float(bboxes_norm[0, 0] * w0)&#10;                cy_center = float(bboxes_norm[0, 1] * h0)&#10;            else:&#10;                cx_center = w0 / 2.0&#10;                cy_center = h0 / 2.0&#10;            # 计算裁剪左上&#10;            if over_w:&#10;                left = int(round(cx_center - crop_w / 2))&#10;                left = max(0, min(left, w0 - crop_w))&#10;            if over_h:&#10;                top = int(round(cy_center - crop_h / 2))&#10;                top = max(0, min(top, h0 - crop_h))&#10;            # 执行裁剪&#10;            img = img[top: top + crop_h, left: left + crop_w]&#10;&#10;        h1, w1 = img.shape[:2]&#10;&#10;        # 单边超限情形下：若另一边 &lt; S，需要 pad 到 S（只在发生裁剪场景下执行）&#10;        if need_crop:&#10;            if over_h and not over_w and w1 &lt; S:&#10;                # pad 宽（左右）&#10;                pad_total = S - w1&#10;                pad_left = pad_total // 2&#10;                pad_right = pad_total - pad_left&#10;                img = cv2.copyMakeBorder(img, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(114, 114, 114))&#10;                w1 = S&#10;            elif over_w and not over_h and h1 &lt; S:&#10;                # pad 高（上下）&#10;                pad_total = S - h1&#10;                pad_top = pad_total // 2&#10;                pad_bottom = pad_total - pad_top&#10;                img = cv2.copyMakeBorder(img, pad_top, pad_bottom, 0, 0, cv2.BORDER_CONSTANT, value=(114, 114, 114))&#10;                h1 = S&#10;        # (双边超) 已经 SxS；(双边不超) 保持原形&#10;&#10;        # 处理标签&#10;        bboxes_norm = label[&quot;bboxes&quot;]&#10;        if bboxes_norm.shape[0] &gt; 0:&#10;            boxes_xyxy = self._norm_xywh_to_pixel_xyxy(bboxes_norm, w0, h0)&#10;            if need_crop:&#10;                # 平移（裁剪）&#10;                boxes_xyxy[:, [0, 2]] -= left&#10;                boxes_xyxy[:, [1, 3]] -= top&#10;            # 平移（pad）&#10;            if pad_left or pad_top:&#10;                boxes_xyxy[:, [0, 2]] += pad_left&#10;                boxes_xyxy[:, [1, 3]] += pad_top&#10;            # 截断到当前图尺寸&#10;            boxes_xyxy[:, 0] = boxes_xyxy[:, 0].clip(0, w1)&#10;            boxes_xyxy[:, 2] = boxes_xyxy[:, 2].clip(0, w1)&#10;            boxes_xyxy[:, 1] = boxes_xyxy[:, 1].clip(0, h1)&#10;            boxes_xyxy[:, 3] = boxes_xyxy[:, 3].clip(0, h1)&#10;            # 过滤极小框&#10;            bw = boxes_xyxy[:, 2] - boxes_xyxy[:, 0]&#10;            bh = boxes_xyxy[:, 3] - boxes_xyxy[:, 1]&#10;            valid = (bw &gt; 2) &amp; (bh &gt; 2)&#10;            boxes_xyxy = boxes_xyxy[valid]&#10;            label[&quot;cls&quot;] = label[&quot;cls&quot;][valid]&#10;            bboxes_new = self._pixel_xyxy_to_norm_xywh(boxes_xyxy, w1, h1)&#10;            label[&quot;bboxes&quot;] = bboxes_new.astype(np.float32)&#10;            label[&quot;normalized&quot;] = True&#10;            label[&quot;bbox_format&quot;] = &quot;xywh&quot;&#10;        # 更新形状&#10;        label[&quot;shape&quot;] = (h1, w1)&#10;        label[&quot;img&quot;] = img&#10;        label[&quot;ori_shape&quot;] = (h1, w1)  # 供后续 transforms 使用&#10;        label[&quot;resized_shape&quot;] = (h1, w1)&#10;        label[&quot;crop_offset&quot;] = (top, left)&#10;        label[&quot;pad_offset&quot;] = (pad_top, pad_left)&#10;        label[&quot;full_ori_shape&quot;] = full_ori_shape&#10;&#10;        if self.transforms:&#10;            label = self.transforms(label)&#10;        return label&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>